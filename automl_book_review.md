## Chapter 1. Hyperparameter Optimization

В этой главе рассмотрены основные алгоритмы поиска гиперпараметров.

Model-free:  
* grid search:
    Для каждого гиперпараметра выбирается множество значений,а затем оценивается каждый 
    элемент(определенный набор гиперпараметров) прямого произведения этих множеств.
* random grid search:
    Выбираются произвольные наборы гиперпараметров, способ хорош когда несколько гиперпараметров
    гораздо важнее остальных   
        
Population-based:
* CMA-ES(covariance matrix adaption evolutionary strategy ):
    Генерирует популяцию наборов гиперпараметров из многомерной Гауссианы, где параметры распределения
    обновляются от поколения к поколению основываясь на успешных представителях предыдущей популяции. 


Bayesian Optimization:
* Основная идея состоит в следующих ключевых компонентах: вероятностная 'суррогатная' модель (предсказывает 
  функцию потерь для данного набора гиперпараметров) и функционал для выбора нового набора гиперпараметров 
  для реальной оценки функции потерь и уточнения параметров модели-суррогата. Чаще всего в качестве такого
  функционала берут expected improvement. В качестве модели суррогата можно брать гауссовские процессы, 
  random forest и нейросети.

Multi-Fidelity Optimization:
* Полное обучение модели на большом датасете может занимать до нескольких часов, это значит что оценка 
  даже одного набора гиперпараметров обходится непозволительно дорого. Предлагается использовать упрощенное 
  представление о функции потерь(low-fidelity), обучая модель на подмножестве всех объектов и признаков, с
  ограничением на число итераций.
* Один из способов уменьшения временных затрат является преждевременная остановка алгоритма по динамике
  кривой обучения(learning curve).
* Successive halving - на каждом шаге алгоритма отбрасывается худшая половина исследуемых наборов 
  гиперпараметров, ресурсы(выборка, время, вычислительные ресурсы) удваиваются и  делается аналогичный шаг.

Также оговаривается что проблема автоматического обучения часто рассматривается шире, включая в себя автоматический отбор признаков, предобработку данных и выбор алгоритма.

## Chapter 2. Meta-Learning

В этой главе рассматриваются различные подходы в meta-learning.  
  
Learning from Model Evaluations:
* Каждое задание из множества **T** может быть описано как вектор **P** оценок конфигураций $\bf \theta$, простарнство конфигураций может быть представлено гиперпараметрами модели, компонентами архитектуры нейронных сетей и т.д. Необходимо обучить meta-learner **L**, который бы мог для новой задачи найти оптимальную конфигурацию.

* Если о новой задаче ничего не известно, т.е мы не имеем никаких оценок конфигураций для этой задачи, предлагается провести ранжирование конфигураций по известным для них оценкам.  Затем выбрать из K лучших по рангу конфигураций ту, что показала себя лучше всего на новой задаче. Или использовать эти оценки как warm-start для дальнейшей оптимизации.

* Другой подход при неизвестном $P_{new}$ это обучить какую-то дифференцируемую функцию(**surrogate model**), обученную предсказываеть оценку для конфигураций $f_j(\theta_i) = P_{j,i}$. Затем с помощью градиентного спуска находятся $\theta_j^*$. Эти конфигурации для задач близких к новой могут быть полезны для дальнейшей оптимизации. 

* Еще один подход состоит в использовании специальных функций, сэмплирующих конфигурации с наилучшей предсказанной оценкой(**acquisition function**). Предлагается обучить для новой задачи ($\bf t_{new}$), а так же для уже известных задач **surrogate model**. Затем использовать взвешенный **expected improvement** этих моделей при сэмплировании оптимальных конфигураций для $\bf t_{new}$.

* Чтобы отобрать задачи, которые связаны с новой, существует множество подходов. В статье  [**Ramachandran, et.al.: Selecting optimal source for transfer learning in Bayesian optimisation.**](https://books.google.ru/books?id=McpmDwAAQBAJ&pg=PA42&lpg=PA42&dq=Ramachandran+Selecting+optimal+source+for+transfer+learning+in+Bayesian+optimisation.&source=bl&ots=xHhpuHu1Nq&sig=ynRb1s6aEE9YaKHSvVH3OfybL34&hl=en&sa=X&ved=2ahUKEwj00v27kPXeAhWPKCwKHQLSBsQQ6AEwBHoECAQQAQ#v=onepage&q=Ramachandran%20Selecting%20optimal%20source%20for%20transfer%20learning%20in%20Bayesian%20optimisation.&f=false) описан подход с использованием **rl**. Действиями в таком случае выступает выбор той или иной задачи(**source**), которая предположительно близка к новой. Награды пересчитываются следующим образом. Данные source задачи соединяются с данными целевой задачи и на этих данных строится **GP**. Затем с помощью **acquisition function** сэмплируется следующая точка, в ней подсчитывается оценка. Вознаграждением будет квадрат разницы подсчитанной оценки($y$) и предсказанного **GP** среднего в новой точке($\hat{y}$). Вознаграждение используется для пересчета весов каждой из предполагаемых source задач. Веса участвуют в выборе source задачи.

* С этой же целью можно использовать learning curves, которые строятся по мере увеличения выборки. Также анализ таких кривых может сильно ускорить выбор оптимальной конфигурации.

Learning from Task Properties

* В таких методах используются мета признаки, описывающие задачи. На их основе можно выбирать различными способами наиболее близкие к новой.

* Конфигурации для новой задачи можно выбирать с помощью рекомендаций. Задачи рассматриваются как пользователи, а конфигурации как товары. Проблема холодного старта решается следующей процедурой, предложенной в статье [**Feurer et al., 2015**](https://ml.informatik.uni-freiburg.de/papers/15-NIPS-auto-sklearn-preprint.pdf): для датасетов каждого из заданий подсчитываются метапризнаки, выбираются те их конфигурации, которые лучше всего себя показали. Затем для нового датасета выбираются самые близкие к нему задачи, с помощью например L1 метрики на векторах мета-признаков. Лучшие конфигурации самых близких датасетов используются для 'горячего' старта. Решение с помощью рекомендаций также подразумевает создание полезных эмбедингов как для задач так и для конфигураций.

* В статье [**Learning based assistant for data pre-processing**](https://arxiv.org/pdf/1803.01024.pdf) предлагается способ автоматической рекомендации способа предобработки данных, а в [**Automated Image Data Preprocessing with Deep Reinforcement Learning**](https://arxiv.org/pdf/1806.05886v1.pdf) авторы предлагают метод для предобработки изображений.

* В [**AlphaD3M: Machine Learning Pipeline Synthesis**](https://www.cs.columbia.edu/~idrori/AlphaD3M.pdf) применяется self-play RL для построения оптимальной конфигурации.
